{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Least-Square Inversion of Airborne Frequency Domain Surveys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on:** Notebook by Marco Couto\n",
    "\n",
    "Workflow reviewed to open real data and run single sounding l2 inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimPEG functionality\n",
    "import simpeg.electromagnetics.frequency_domain as fdem\n",
    "from simpeg.utils import plot_1d_layer_model, download, mkvc\n",
    "from simpeg import (\n",
    "    maps,\n",
    "    data,\n",
    "    data_misfit,\n",
    "    regularization,\n",
    "    optimization,\n",
    "    inverse_problem,\n",
    "    inversion,\n",
    "    directives,\n",
    ")\n",
    "\n",
    "# discretize functionality\n",
    "from discretize import TensorMesh\n",
    "\n",
    "# Common Python functionality\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.constants import mu_0\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "import dill\n",
    "%matplotlib inline\n",
    "mpl.rcParams.update({\"font.size\": 12})\n",
    "\n",
    "## For the paralellization\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "write_output = False  # Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1476016096.py, line 191)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 191\u001b[0;36m\u001b[0m\n\u001b[0;31m    ax[1].loglog(freqs, inphase_station_data[:,i], \"-o\", lw=2, , label = line_station[line_station.fid == fid].fid.values)\u001b[0m\n\u001b[0m                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Function to plot tikhonov curves\n",
    "\n",
    "def plot_tikhonov_curves(beta_values, phi_d, phi_m, phid_star=None, iteration=None, ax=None):\n",
    "    ### This function is from Lindseýs class (EOSC 454/556B - Winter 2024), quite helpful.\n",
    "\n",
    "    \"\"\"\n",
    "    Plot Tikhonov curves to visualize the trade-offs between data misfit (phi_d) and model norms (phi_m) \n",
    "    across a range of regularization parameters (beta_values).\n",
    "\n",
    "    This function creates three subplots: \n",
    "    1. beta_values vs phi_d\n",
    "    2. beta_values vs phi_m\n",
    "    3. phi_m vs phi_d\n",
    "    If a target phi_d value (phid_star) is provided, it is plotted as a dashed line in the first and third subplots.\n",
    "    Specific iterations can be highlighted with markers if provided.\n",
    "\n",
    "    Parameters:\n",
    "        beta_values (array-like): Array of regularization parameter values (beta).\n",
    "        phi_d (array-like): Array of data misfit values corresponding to each beta.\n",
    "        phi_m (array-like): Array of model norm values corresponding to each beta.\n",
    "        phid_star (float, optional): Target value of data misfit to plot as a reference line. Defaults to None.\n",
    "        iteration (int, optional): Index of a specific iteration to highlight in the plots. Defaults to None.\n",
    "        ax (array of matplotlib.axes.Axes, optional): Pre-existing axes for the plot. If None, axes will be created.\n",
    "        \n",
    "    Returns:\n",
    "        ax (array of matplotlib.axes.Axes): The array of matplotlib axes with the plots.\n",
    "\n",
    "    Notes:\n",
    "        This function is from Lindsey's class (EOSC 454/556B - Winter 2024), and is designed to be a helpful\n",
    "        visual tool in understanding the balance between fitting the data and regularization.\n",
    "\n",
    "    Examples:\n",
    "        >>> beta_values = np.logspace(-3, 1, 50)\n",
    "        >>> phi_d = 1 / beta_values\n",
    "        >>> phi_m = beta_values ** 2\n",
    "        >>> plot_tikhonov_curves(beta_values, phi_d, phi_m, phid_star=0.1, iteration=25)\n",
    "    \"\"\"\n",
    "    \n",
    "    if ax is None: \n",
    "        fig, ax = plt.subplots(1, 3, figsize=(12,3))\n",
    "    \n",
    "    ax[0].plot(beta_values, phi_d)\n",
    "    ax[1].plot(beta_values, phi_m)\n",
    "    ax[2].plot(phi_m, phi_d)\n",
    "\n",
    "    if phid_star is not None: \n",
    "        ax[0].plot(beta_values, np.ones_like(beta_values) * phid_star, \"--k\")\n",
    "        ax[2].plot(phi_m, np.ones_like(beta_values) * phid_star, \"--k\")\n",
    "\n",
    "    ax[0].set_ylabel(\"$\\\\phi_d$\")\n",
    "    ax[1].set_ylabel(\"$\\\\phi_m$\")\n",
    "    ax[2].set_ylabel(\"$\\\\phi_d$\")\n",
    "    ax[2].set_xlabel(\"$\\\\phi_m$\")\n",
    "    \n",
    "    if iteration is not None: \n",
    "        ax[0].loglog(beta_values[iteration], phi_d[iteration], \"C3o\")\n",
    "        ax[1].loglog(beta_values[iteration], phi_m[iteration], \"C3o\")\n",
    "        ax[2].loglog(phi_m[iteration], phi_d[iteration], \"C3o\")\n",
    "\n",
    "    for a in ax[:2]:\n",
    "        a.invert_xaxis()\n",
    "        a.set_xlabel(\"$\\\\beta$\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "#Function to plot geographical trasmitter location\n",
    "def plot_survey_lines(fdem_data, line_no, return_results=True, plot_results=True):\n",
    "    \"\"\"\n",
    "    Plot the geographical distribution of transmitter locations for a specific survey line within a dataset.\n",
    "\n",
    "    This function takes a line number, groups the data by line, and plots the transmitter locations for\n",
    "    all lines in a faint scatter plot and highlights the transmitter locations for the specified line in a\n",
    "    more pronounced scatter plot. The figure's axes are labeled with easting and northing in meters.\n",
    "\n",
    "    Parameters:\n",
    "        line_no (int or str): Identifier for the survey line whose data is to be plotted.\n",
    "        display_results (bool, optional): If True, the function returns the data frame and station\n",
    "                                          identifiers for the specified line. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Only if display_results is True. Returns a tuple containing:\n",
    "               - pandas.DataFrame: Data frame for the specified line.\n",
    "               - numpy.ndarray: Array of station identifiers for the specified line based on the fiducial code.\n",
    "\n",
    "    Notes:\n",
    "        This function assumes the existence of a globally accessible pandas DataFrame named `fdem_data` with\n",
    "        at least the following columns: ['Line', 'fid', 'x_tx', 'y_tx']. It also assumes that the data has\n",
    "        already been loaded and is available for processing.\n",
    "\n",
    "    Examples:\n",
    "        >>> plot_line_survey(101)\n",
    "        >>> line_data, stations = plot_line_survey(101, display_results=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    line_grouping = fdem_data.groupby('Line')\n",
    "    line = line_grouping.get_group(line_no)\n",
    "    line_stations = line.fid.values\n",
    "\n",
    "    if plot_results:\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))        \n",
    "        ax.scatter(fdem_data.x_tx, fdem_data.y_tx, s=0.5)\n",
    "        ax.scatter(line.x_tx, line.y_tx, s=0.5)\n",
    "        ax.set_xlabel('Easting (m)')\n",
    "        ax.set_ylabel('Northing (m)')\n",
    "        ax.ticklabel_format(axis='both', style='sci', scilimits=(6,5))\n",
    "        ax.set_title(line_no)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    if return_results:\n",
    "        return line, line_stations\n",
    "\n",
    "#Plot line of data\n",
    "def plot_station_line_data(line, line_no, fid_list, freqs=[None], freqs_names=[None], display_results=False, plot_coaxial=False, plot_results=True):\n",
    "    \"\"\"\n",
    "    Plot data for a specific survey station on a given line, including the geographical plot of the\n",
    "    flight line and sounding data. This function creates several visualizations to analyze the frequency response\n",
    "    at a specific station compared to the entire flight line data.\n",
    "\n",
    "    Parameters:\n",
    "        line_no (int or str): Identifier for the survey line whose data is to be plotted.\n",
    "        fid (int or str): Identifier for the specific station (fiducial) on the flight line to highlight.\n",
    "        display_results (bool, optional): If True, returns detailed data arrays for the specific station. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Only if display_results is True. Returns a tuple containing:\n",
    "               - pandas.DataFrame: Data frame for the specific station.\n",
    "               - int or str: Fiducial identifier.\n",
    "               - list: In-phase data for the specific station across all frequencies.\n",
    "               - list: Quadrature data for the specific station across all frequencies.\n",
    "\n",
    "    Notes:\n",
    "        Assumes availability of a globally accessible pandas DataFrame `fdem_data` with columns including 'Line', 'fid', 'x_tx', 'y_tx',\n",
    "        and data fields formatted as 'cxi{frequency}' or 'cpi{frequency}' for in-phase data and 'cxq{frequency}' or 'cpq{frequency}'\n",
    "        for quadrature data. The 'freqs' variable should be an iterable containing the frequency labels used in the data fields.\n",
    "        This function also uses 'all_freqs_num', which should be the numerical values of frequencies for plotting.\n",
    "\n",
    "    Examples:\n",
    "        >>> plot_station_line_data(101, 205)\n",
    "        >>> station_data, station_fid, inphase_data, quad_data = plot_station_line_data(101, 205, display_results=True)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #choose current line\n",
    "    line_grouping = fdem_data.groupby('Line')\n",
    "    line = line_grouping.get_group(line_no)\n",
    "\n",
    "    #choose list of stations\n",
    "    filtered_line = line[line[\"fid\"].isin(fid_list)]\n",
    "    \n",
    "    # Select only numeric columns for mean calculation\n",
    "    numeric_filtered_line = filtered_line.select_dtypes(include=[\"number\"])\n",
    "    \n",
    "    # Group by 'fid' and calculate the mean for numeric columns only\n",
    "    line_station = numeric_filtered_line.groupby(\"fid\", as_index=False).mean()\n",
    "\n",
    "\n",
    "    ### Getting the data for the sounding point and the data for the whole line\n",
    "    inphase_station_data = []\n",
    "    quad_station_data = []\n",
    "    inphase_line_data = []\n",
    "    quad_line_data = []\n",
    "\n",
    "\n",
    "    for f in freqs_names:\n",
    "        if plot_coaxial == True:\n",
    "            inphase_station_data.append(line_station[f'cxi{f}'])\n",
    "            quad_station_data.append(line_station[f'cxq{f}'])\n",
    "            nphase_line_data.append(line[f'cxi{f}'])\n",
    "            quad_line_data.append(line[f'cxq{f}'])\n",
    "        else:\n",
    "            inphase_station_data.append(line_station[f'cpi{f}'])\n",
    "            quad_station_data.append(line_station[f'cpq{f}'])\n",
    "            inphase_line_data.append(line_station[f'cpi{f}'])\n",
    "            quad_line_data.append(line_station[f'cpq{f}'])\n",
    "\n",
    "    inphase_station_data = np.array(inphase_station_data)\n",
    "    quad_station_data = np.array(quad_station_data)\n",
    "    inphase_line_data = np.array(inphase_line_data)\n",
    "    quad_line_data = np.array(quad_line_data)\n",
    "    \n",
    "    if plot_results:\n",
    "\n",
    "        ### Sounding plot\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(9, 5))\n",
    "    \n",
    "        ax[0].scatter(line.x_tx, line.y_tx, s=0.5)\n",
    "        #if fid in line.fid.values:\n",
    "        for i,fid in enumerate(fid_list):\n",
    "            ax[0].scatter(line_station[line_station.fid == fid].x_tx, line_station[line_station.fid == fid].y_tx, s=40, marker='o', label = line_station[line_station.fid == fid].fid.values)\n",
    "            ax[1].loglog(freqs, inphase_station_data[:,i], \"-o\", lw=2, , label = line_station[line_station.fid == fid].fid.values)\n",
    "            ax[1].loglog(freqs, quad_station_data[:,i], \":o\", lw=2, , label = line_station[line_station.fid == fid].fid.values)\n",
    "        ax[0].set_xlabel('Easting (m)')\n",
    "        ax[0].set_ylabel('Northing (m)')\n",
    "        ax[0].ticklabel_format(style='sci')\n",
    "        ax[0].set_title('Flight Line')\n",
    "        ax[0].ticklabel_format(axis='both', style='sci', scilimits=(6,5))\n",
    "        ax[0].legend()\n",
    "    \n",
    "        ax[1].grid(which=\"both\")\n",
    "        ax[1].set_xlabel(\"Frequency (Hz)\")\n",
    "        ax[1].set_ylabel(\"|Hs/Hp| (ppm)\")\n",
    "        ax[1].set_title(\"Sounding Data\")\n",
    "        ax[1].legend([\"Real\", \"Imaginary\"])\n",
    "    \n",
    "        fig.suptitle(f'{line_no} - Fiducial: {fid}', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        ### Profile plot\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(9, 6))\n",
    "        for i, f in enumerate(freqs):\n",
    "            ax[0].semilogy(line_station.dist, inphase_line_data[i, :], \"-o\", lw=1, label = f\"{freqs_names[i]}\")\n",
    "            ax[1].semilogy(line_station.dist, quad_line_data[i, :], \"-o\",  lw=1, label = f\"{freqs_names[i]}\")\n",
    "        \n",
    "        for i,fid in enumerate(fid_list):\n",
    "            ax[0].axvline(line_station[line_station.fid == fid].dist.values[0], linestyle='--')\n",
    "            #ax[0].text(line_station[line_station.fid == fid].dist.values[0], 0.1, line_station[line_station.fid == fid].fid.values, ha='center', va='bottom', color='black', fontsize=10)\n",
    "            \n",
    "            ax[1].axvline(line_station[line_station.fid == fid].dist.values[0], linestyle='--')\n",
    "            #ax[1].text(line_station[line_station.fid == fid].dist.values[0], 0.1, line_station[line_station.fid == fid].fid.values, ha='center', va='bottom', color='black', fontsize=10)\n",
    "            \n",
    "        ax[1].set_xlabel(\"Profile Distance (m)\")\n",
    "        ax[0].set_ylabel(\"|Hs/Hp| (ppm)\")\n",
    "        ax[1].set_ylabel(\"|Hs/Hp| (ppm)\")\n",
    "        ax[0].legend()\n",
    "        ax[1].legend()\n",
    "        ax[0].set_title(\"Real\")\n",
    "        ax[1].set_title(\"Imaginary\")\n",
    "        ax[0].grid(which=\"both\", linestyle=\"--\", color='gray')\n",
    "        ax[1].grid(which=\"both\", linestyle=\"--\", color='gray')\n",
    "    \n",
    "        # fig.suptitle(f'{line_no} - Fiducial: {fid}', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    if display_results:\n",
    "        return line_station, fid, inphase_station_data, quad_station_data\n",
    "\n",
    "#Calculate the coordinates of transmitter and receiver\n",
    "def calculate_tx_rx_coordinates(line, plot_histogram=False):\n",
    "    \"\"\"\n",
    "    Calculates the transmitter (Tx) and receiver (Rx) coordinates for various frequencies\n",
    "    based on azimuth values from the input dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - line (pd.DataFrame): Input dataframe containing x_tx and y_tx columns.\n",
    "    - plot_histogram (bool): Whether to plot a histogram of azimuth values. Default is False.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Updated dataframe with calculated Tx and Rx coordinates.\n",
    "    \"\"\"\n",
    "    theta = []  # To store the co-azimuth in radians\n",
    "    Az_rad = []  # To store the azimuth values in radians\n",
    "\n",
    "    # Dictionary with Tx-Rx coil separation\n",
    "    d = {\n",
    "        'cp140k': 7.95,\n",
    "        'cp40k': 7.93,\n",
    "        'cp8200': 7.95,\n",
    "        'cx3300': 9.06,\n",
    "        'cp1800': 7.94,\n",
    "        'cp400': 7.93\n",
    "    }\n",
    "\n",
    "    # Initialize arrays for Tx and Rx coordinates\n",
    "    num_points = line.x_tx.values.shape[0]\n",
    "    coords = {f\"{key}_{suffix}\": np.zeros(num_points) for key in d for suffix in [\"tx_x\", \"tx_y\", \"rx_x\", \"rx_y\"]}\n",
    "\n",
    "    # Calculate coordinates based on azimuth\n",
    "    for i in range(num_points - 1):\n",
    "        deltay = line.y_tx.values[i + 1] - line.y_tx.values[i]\n",
    "        deltax = line.x_tx.values[i + 1] - line.x_tx.values[i]\n",
    "        # angle = np.arctan2(deltay, deltax)\n",
    "        angle = np.arctan(deltay / deltax)\n",
    "        theta.append(angle)\n",
    "        # print(f'angle = {angle}')\n",
    "        Az_rad.append(angle if angle >= 0 else 2 * np.pi + angle)\n",
    "\n",
    "        for key, dist in d.items():\n",
    "            dx = (dist / 2) * np.sin(angle)\n",
    "            dy = (dist / 2) * np.cos(angle)\n",
    "\n",
    "            coords[f\"{key}_tx_x\"][i] = line.x_tx.values[i] + dx\n",
    "            coords[f\"{key}_tx_y\"][i] = line.y_tx.values[i] + dy\n",
    "            coords[f\"{key}_rx_x\"][i] = line.x_tx.values[i] - dx\n",
    "            coords[f\"{key}_rx_y\"][i] = line.y_tx.values[i] - dy\n",
    "\n",
    "    Az_rad = np.array(Az_rad)\n",
    "    Az_deg = Az_rad * 180 / np.pi\n",
    "\n",
    "    if plot_histogram:\n",
    "        plt.hist(Az_deg, bins=100)\n",
    "        plt.title(\"Azimuth Distribution (Degrees)\")\n",
    "        plt.xlabel(\"Azimuth (degrees)\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.show()\n",
    "\n",
    "        print(f'Mean azimuth: {np.mean(Az_deg):.2f} degrees')\n",
    "        print(f'Std azimuth: {np.std(Az_deg):.2f} degrees')\n",
    "        print('-----------------------------------\\n')\n",
    "\n",
    "    # Assign calculated Tx-Rx coordinates to the dataframe\n",
    "    for key, values in coords.items():\n",
    "        line[key] = values\n",
    "\n",
    "    return line\n",
    "\n",
    "#Calculate cumulative distances\n",
    "def calculate_cumulative_distance(df, x_col='X', y_col='Y'):\n",
    "    \"\"\"\n",
    "    Calculate the cumulative distance from the first point in a profile.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataframe containing the X and Y coordinates.\n",
    "    x_col (str): The name of the column containing the X coordinates. Default is 'X'.\n",
    "    y_col (str): The name of the column containing the Y coordinates. Default is 'Y'.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The input dataframe with an additional column 'dist' containing the cumulative distances.\n",
    "    \"\"\"\n",
    "    # Extract the X and Y coordinates\n",
    "    x = df[x_col].values\n",
    "    y = df[y_col].values\n",
    "    \n",
    "    # Calculate the differences between consecutive points\n",
    "    dx = np.diff(x)\n",
    "    dy = np.diff(y)\n",
    "    \n",
    "    # Calculate the Euclidean distance between consecutive points\n",
    "    distances = np.sqrt(dx**2 + dy**2)\n",
    "    \n",
    "    # Prepend a 0 to the distances array to represent the distance from the first point to itself\n",
    "    distances = np.insert(distances, 0, 0)\n",
    "    \n",
    "    # Calculate the cumulative distance\n",
    "    cumulative_distances = np.cumsum(distances)\n",
    "    \n",
    "    # Add the cumulative distances to the dataframe\n",
    "    df['dist'] = cumulative_distances\n",
    "    \n",
    "    return df\n",
    "\n",
    "def make_directory(directory_name, absolute_path=False):\n",
    "    \"\"\"\n",
    "    Checks if a directory exists one level above the current working directory.\n",
    "    If it does not exist, the directory is created.\n",
    "\n",
    "    :param directory_name: Name of the directory to check or create.\n",
    "    :return: The relative path to the directory (e.g., \"../my_directory\").\n",
    "    \"\"\"\n",
    "    # Get the current working directory\n",
    "    work_directory = os.getcwd()\n",
    "\n",
    "    # Get the parent directory (one level above)\n",
    "    parent_directory = os.path.dirname(work_directory)\n",
    "\n",
    "    # Create the full path for the directory\n",
    "    directory_path = os.path.join(parent_directory, directory_name)\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(directory_path):\n",
    "        # Create the directory if it does not exist\n",
    "        os.makedirs(directory_path)\n",
    "        print(f\"Directory '{directory_name}' created in '{parent_directory}'.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory_name}' already exists in '{parent_directory}'.\")\n",
    "\n",
    "\n",
    "    if absolute_path:\n",
    "        # Return the absolute path (e.g., \"/home/user/my_directory\")\n",
    "        return directory_path\n",
    "    else:\n",
    "        # Return the relative path (e.g., \"../my_directory\")\n",
    "        return f\"../{directory_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_grouping = fdem_data.groupby('Line')\n",
    "line = line_grouping.get_group(line_no)\n",
    "line.fid.values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion function\n",
    "\n",
    "* Reading the data\n",
    "* Defining Sources and Receivers\n",
    "* Defining the data\n",
    "* Halfspace inversion, pick 3 soundings, use this as reference model\n",
    "* Inversion with Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data\n",
    "\n",
    "* Importing the data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../database/'\n",
    "\n",
    "csv_files = []\n",
    "csv_titles = []\n",
    "extension = \"csv\"\n",
    "\n",
    "for root, dirs, files in os.walk(data_dir, topdown=False):\n",
    "    for f in files:\n",
    "        if f.split(\".\")[-1].upper() == extension.upper():\n",
    "            csv_titles.append(f.split(\".\")[-2])\n",
    "            csv_files.append(os.path.join(root, f))\n",
    "\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from csv: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory (where the notebook is running)\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Move one level up to the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Construct the full path to the CSV file in the parent directory\n",
    "csv_path = os.path.join(parent_dir, \"block53_fdem_inv.csv\")\n",
    "\n",
    "fdem_data = pd.read_csv(csv_path) ## Set to the position of the csv_files list where the database you want is\n",
    "pd.set_option('display.max_columns', len(fdem_data.columns))\n",
    "fdem_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdem_data.rename(columns={'X': 'x_tx', 'Y':'y_tx', 'Z':'gpsz_tx'}, inplace=True) ## Change the name of the coordinates columns here, if needed:\n",
    "np.array(fdem_data.columns) ## Shows all the columns names inside the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the system parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the system frequencies below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_freqs_num = np.r_[135, 40, 8.2, 3.3, 1.8, 0.4]*1e3 ## Creates a numpy array with all frequencies\n",
    "all_freqs_num[::-1].sort()\n",
    "all_freqs_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don`t want to invert coaxial frequencies, define them below: ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_cx = [3300] ## Coaxial frequencies - numpy array\n",
    "all_freqs_num = np.delete(all_freqs_num, np.where(all_freqs_num == freq_cx)) ## Removes the coaxial frequencies from the list\n",
    "all_freqs_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a list with the frequencies in string format too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_freqs = ['140k', '40k', '8200', '3300', '1800', '400'] ## All frequencies\n",
    "freq_cx_str = ['3300'] ## Coaxial frequencies - string array\n",
    "all_freqs = np.array([f for f in all_freqs if f not in freq_cx_str]) ## Removes the coaxial frequencies from the list\n",
    "all_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System geometry and physical parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Source orientation\n",
    "source_orientation = [\"z\", \"z\", \"z\", \"z\", \"z\"] # \"x\", \"y\" or \"z\" - here we are using only the CP frequencies\n",
    "moments = [17, 49, 72, 187, 359]  ## Tx dipole moments fromm Xcalibur´s report -  only cp geometry\n",
    "\n",
    "## Receiver orientation\n",
    "receiver_orientation = [\"z\", \"z\", \"z\", \"z\", \"z\"]  # \"x\", \"y\" or \"z\" - here we are using only the CP frequencies\n",
    "data_type = 'ppm'  # \"secondary\", \"total\" or \"ppm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining inversion parameters and testing on a specific sounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipywidgets.interact(\n",
    "    plot_survey_lines,\n",
    "    fdem_data = ipywidgets.fixed(fdem_data),\n",
    "    line_no = ipywidgets.SelectionSlider(\n",
    "            options=fdem_data.Line.values,\n",
    "            value=fdem_data.Line.values[0],\n",
    "            description='Line: ',\n",
    "            # disabled=False,\n",
    "            # continuous_update=False,\n",
    "            # orientation='horizontal',\n",
    "            # readout=True\n",
    "        ),\n",
    "    return_results = ipywidgets.fixed(False),\n",
    "    plot_resutls = ipywidgets.fixed(True)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Line data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_no = 'L530100' ### \"regular\" flight line\n",
    "lines = fdem_data['Line'].unique()\n",
    "line, line_fids = plot_survey_lines(fdem_data, line_no, return_results=True, plot_results=True) ## Plots the map with the selected line for confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_station_line_data(fdem_data, line_no, [2490.8, 2490.5], freqs = all_freqs_num, freqs_names=all_freqs, display_results=False, plot_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the soundings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_grouping = fdem_data.groupby('Line')\n",
    "line = line_grouping.get_group(line_no)\n",
    "\n",
    "#Find all not nan fid values:\n",
    "non_nan_fid = line[line['fid'].notna()]['fid'].values\n",
    "\n",
    "#choose every 200 sounding of the last part \n",
    "list_fid = (non_nan_fid[3000:])[::100]\n",
    "\n",
    "\n",
    "plot_station_line_data(fdem_data, line_no, list_fid, freqs = all_freqs_num, freqs_names=all_freqs, display_results=False, plot_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the inversion for one sounding point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose a single fid: from line\n",
    "fid_n = list_fid[0]\n",
    "line_station = line[line.fid == fid].iloc[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining source and receiver data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inversion: parameters:\n",
    "freqs = all_freqs_num\n",
    "freqs_names = all_freqs\n",
    "freq_avoid = [400., 1800., 8200.]\n",
    "rm_real=True\n",
    "rm_imag=True\n",
    "\n",
    "\n",
    "#Define the Source orientation \n",
    "tx_orient = [\"z\", \"z\", \"z\", \"z\", \"z\"]\n",
    "moments = [17, 49, 72, 187, 359]\n",
    "\n",
    "# Define receiver orientation and type\n",
    "rx_orient = [\"z\", \"z\", \"z\", \"z\", \"z\"] \n",
    "dtype = \"ppm\"\n",
    "\n",
    "#Calculate the height (terrain clearance)\n",
    "line_station.loc['height_tx'] = line_station['gpsz_tx'] - line_station['dtm']\n",
    "\n",
    "######################################\n",
    "### Defining Sources and Receivers ###\n",
    "######################################\n",
    "\n",
    "# Generate the labels with frequency values strings\n",
    "source_locations = np.array([[\n",
    "            getattr(line_station, f'cp{freq}_tx_x'),  # Transmitter X\n",
    "            getattr(line_station, f'cp{freq}_tx_y'),  # Transmitter Y\n",
    "            getattr(line_station, 'height_tx')  # Common height for the transmitter\n",
    "            ] for freq in all_freqs])\n",
    "\n",
    "receiver_locations = np.array([[\n",
    "            getattr(line_station, f'cp{freq}_rx_x'),  # Transmitter X\n",
    "            getattr(line_station, f'cp{freq}_rx_y'),  # Transmitter Y\n",
    "            getattr(line_station, 'height_tx')  # Common height for the transmitter\n",
    "            ] for freq in all_freqs])\n",
    "\n",
    "\n",
    "#Create source and receiver list\n",
    "source_list = []\n",
    "\n",
    "for i, freq in enumerate(freqs):\n",
    " \n",
    "    receiver_list = []\n",
    "\n",
    "    #Add real readings\n",
    "    if rm_real:\n",
    "        if freq not in freq_avoid:\n",
    "            receiver_list.append(\n",
    "                fdem.receivers.PointMagneticFieldSecondary(\n",
    "                    locations=np.c_[receiver_locations[i]].T,\n",
    "                    orientation=rx_orient[i],\n",
    "                    data_type=dtype,\n",
    "                    component=\"real\",\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        receiver_list.append(\n",
    "            fdem.receivers.PointMagneticFieldSecondary(\n",
    "                locations=np.c_[receiver_locations[i]].T,\n",
    "                orientation=rx_orient[i],\n",
    "                data_type=dtype,\n",
    "                component=\"real\",\n",
    "            )\n",
    "        )\n",
    "    if rm_imag:\n",
    "            if freq not in freq_avoid:\n",
    "                receiver_list.append(\n",
    "                    fdem.receivers.PointMagneticFieldSecondary(\n",
    "                        locations=np.c_[receiver_locations[i]].T,\n",
    "                        orientation=rx_orient[i],\n",
    "                        data_type=dtype,\n",
    "                        component=\"imag\",\n",
    "                    )\n",
    "                )\n",
    "    else:\n",
    "        receiver_list.append(\n",
    "            fdem.receivers.PointMagneticFieldSecondary(\n",
    "                locations=np.c_[receiver_locations[i]].T,\n",
    "                orientation=rx_orient[i],\n",
    "                data_type=dtype,\n",
    "                component=\"imag\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    #Apprend source\n",
    "    source_list.append(\n",
    "            fdem.sources.MagDipole(\n",
    "                receiver_list=receiver_list,\n",
    "                frequency=freq,\n",
    "                location=np.c_[source_locations[i]].T,\n",
    "                orientation=tx_orient[i],\n",
    "                moment=moments[i],\n",
    "            )\n",
    "        )\n",
    "\n",
    "#########################\n",
    "### Defining the data ###\n",
    "#########################\n",
    "\n",
    "## Defines the survey object\n",
    "survey = fdem.survey.Survey(source_list)\n",
    "survey.nD ## Check the number of Tx and Rx components (Real and Imaginary) - it should be 2 * the number of used frequencies\n",
    "\n",
    "# Get arrays of data from sounding\n",
    "inphase_data = []\n",
    "quad_data = []\n",
    "\n",
    "for f in freqs_names:\n",
    "    inphase_data.append(line_station[f'cpi{f}'])\n",
    "    quad_data.append(line_station[f'cpq{f}'])\n",
    "\n",
    "inphase_data = np.array(inphase_data)\n",
    "quad_data = np.array(quad_data)\n",
    "\n",
    "\n",
    "#get rid of frequencies to avoid:\n",
    "if rm_real and rm_imag:\n",
    "    ind_avoid = [np.where(all_freqs_num == f)[0][0] for f in freq_avoid]\n",
    "elif rm_real:\n",
    "    ind_avoid = [np.where(all_freqs_num == f)[0][0] for f in freq_avoid]\n",
    "elif rm_imag:\n",
    "    ind_avoid = [np.where(all_freqs_num == f)[0][0] for f in freq_avoid]\n",
    "else:\n",
    "    ind_avoid = [None]\n",
    "\n",
    "#Put everything in a single array\n",
    "\n",
    "dobs = []\n",
    "for i in range(len(inphase_data)):\n",
    "\n",
    "    # if i == 3: ## In this analysis, we are not inverting the coaxial data\n",
    "    #     pass\n",
    "    # else:\n",
    "    if rm_real and not rm_imag:\n",
    "        if i not in ind_avoid:\n",
    "            dobs = np.append(dobs, inphase_data[i])\n",
    "        dobs = np.append(dobs, quad_data[i])\n",
    "    elif rm_imag and not rm_real:\n",
    "        dobs = np.append(dobs, inphase_data[i])\n",
    "        if i not in ind_avoid:\n",
    "            dobs = np.append(dobs, quad_data[i])\n",
    "    elif rm_real and rm_imag:\n",
    "        if i not in ind_avoid:\n",
    "            dobs = np.append(dobs, inphase_data[i])\n",
    "            dobs = np.append(dobs, quad_data[i])\n",
    "    else:\n",
    "        dobs = np.append(dobs, inphase_data[i])\n",
    "        dobs = np.append(dobs, quad_data[i])\n",
    "\n",
    "\n",
    "#Create data simpeg object:\n",
    "\n",
    "# Defines the data object and assigns uncertainties with the noise floor\n",
    "uncertainty_floor = 5.0e0\n",
    "relative_error = 0.05 #What is relative error?\n",
    "data_object = data.Data(survey, dobs=dobs, relative_error=relative_error, noise_floor=uncertainty_floor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Halspace Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mesh Definition for halfspace ###\n",
    "\n",
    "layer_thick_halfspace = [10000]\n",
    "n_layers_halfspace = 1\n",
    "\n",
    "# Defining the mapping\n",
    "log_conductivity_halfspace_map = maps.ExpMap(nP=n_layers_halfspace)\n",
    "\n",
    "# Starting model is log-conductivity values (S/m)\n",
    "starting_conductivity_model_hsp = np.log(1e-3 * np.ones(n_layers_halfspace))\n",
    "\n",
    "# Reference model, same as starting \n",
    "reference_conductivity_model_hsp = starting_conductivity_model_hsp.copy()\n",
    "\n",
    "### Forward simulation ###\n",
    "\n",
    "simulation_hsp_L2 = fdem.Simulation1DLayered(\n",
    "        survey=survey,\n",
    "        thicknesses=[],\n",
    "        sigmaMap=log_conductivity_halfspace_map\n",
    "    )\n",
    "\n",
    "### Data Misfit ###\n",
    "\n",
    "dmis_hsp_L2 = data_misfit.L2DataMisfit(simulation=simulation_hsp_L2, data=data_object)\n",
    "\n",
    "### Regularization ###\n",
    "\n",
    "h = np.r_[layer_thick_halfspace]\n",
    "\n",
    "# Create regularization mesh\n",
    "regularization_mesh = TensorMesh([h], \"N\")\n",
    "\n",
    "reg_L2 = regularization.WeightedLeastSquares(\n",
    "        regularization_mesh,\n",
    "        length_scale_x=10.0,\n",
    "        # reference_model=np.r_[reference_conductivity_model, reference_conductivity_model[-1]],\n",
    "        reference_model=reference_conductivity_model_hsp,\n",
    "        reference_model_in_smooth=False\n",
    "        )\n",
    "\n",
    "#Set regularization parameters:\n",
    "reg_L2.alpha_s = 1e-5 \n",
    "reg_L2.alpha_x=1 \n",
    "\n",
    "### Optimization ###\n",
    "opt_L2 = optimization.InexactGaussNewton(\n",
    "    maxIter=100, maxIterLS=20, maxIterCG=20, tolCG=1e-3\n",
    ")\n",
    "\n",
    "### Inversion ###\n",
    "inv_prob_L2 = inverse_problem.BaseInvProblem(dmis_hsp_L2, reg_L2, opt_L2)\n",
    "\n",
    "#Set inversion directives:\n",
    "update_jacobi = directives.UpdatePreconditioner(update_every_iteration=True)\n",
    "starting_beta = directives.BetaEstimate_ByEig(beta0_ratio=5)\n",
    "beta_schedule = directives.BetaSchedule(coolingFactor=1.5, coolingRate=2)\n",
    "target_misfit = directives.TargetMisfit(chifact=1.0)\n",
    "save_L2_hp = directives.SaveOutputDictEveryIteration()\n",
    "\n",
    "directives_list_L2 = [\n",
    "    update_jacobi,\n",
    "    starting_beta,\n",
    "    beta_schedule,\n",
    "    target_misfit,\n",
    "    save_L2_hp\n",
    "]\n",
    "\n",
    "### Running the inversion ###\n",
    "# Combine the inverse problem and the set of directives\n",
    "inv_L2 = inversion.BaseInversion(inv_prob_L2, directives_list_L2)\n",
    "\n",
    "# Run the inversion\n",
    "# print(f\"\\n **** Running halfspace inversion for line {line_no} and station {stn}... ****\")\n",
    "recovered_halfspace_model_L2 = inv_L2.run(starting_conductivity_model_hsp)\n",
    "\n",
    "## Get the recovered halfspace resistivity from model estimated\n",
    "conductivities_hsp = log_conductivity_halfspace_map * recovered_halfspace_model_L2\n",
    "resistivities_hsp = 1 / conductivities_hsp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print halfspace results:\n",
    "print(f\"\\n **** Halfspace inversion for line {line_no} and sounding {fid_n}... ****\")\n",
    "print(\"Resistivity halfspace: \", resistivities_hsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Square Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mesh Definition ###\n",
    "\n",
    "depth_min = 1                       # top layer thickness\n",
    "depth_max = 205.                      # depth to lowest layer\n",
    "geometric_factor = 1.1                # rate of thickness increase\n",
    "\n",
    "#Increase layer thickness by geometric factor until depth_max\n",
    "layer_thicknesses = [depth_min]\n",
    "while np.sum(layer_thicknesses) < depth_max:\n",
    "    layer_thicknesses.append(geometric_factor*layer_thicknesses[-1])\n",
    "\n",
    "#Set number of layers\n",
    "n_layers = len(layer_thicknesses) + 1  # Number of layers\n",
    "\n",
    "### Defining the mapping ###\n",
    "log_conductivity_map = maps.ExpMap(nP=n_layers)\n",
    "\n",
    "### Starting model ##\n",
    "\n",
    "# estimated host conductivity (S/m) from halfspace inversion\n",
    "host_conductivity = 1 / resistivities_hsp[0]\n",
    "\n",
    "# Starting model is log-conductivity values (S/m)\n",
    "starting_conductivity_model = np.log(host_conductivity * np.ones(n_layers))\n",
    "\n",
    "# Reference model is also log-resistivity values (S/m)\n",
    "reference_conductivity_model = starting_conductivity_model.copy()\n",
    "\n",
    "### Forward Simulation ###\n",
    "\n",
    "simulation_L2 = fdem.Simulation1DLayered(\n",
    "    survey=survey,\n",
    "    thicknesses=layer_thicknesses,\n",
    "    sigmaMap=log_conductivity_map\n",
    ")\n",
    "\n",
    "### Data Misfit ###\n",
    "\n",
    "dmis_L2 = data_misfit.L2DataMisfit(simulation=simulation_L2, data=data_object)\n",
    "\n",
    "### Regularization ###\n",
    "\n",
    "# Define 1D cell widths\n",
    "h = np.r_[layer_thicknesses, layer_thicknesses[-1]]\n",
    "h = np.flipud(h)\n",
    "\n",
    "# Create regularization mesh\n",
    "regularization_mesh = TensorMesh([h], \"N\")\n",
    "\n",
    "# Define regularization\n",
    "reg_L2 = regularization.WeightedLeastSquares(\n",
    "        regularization_mesh,\n",
    "        # smallness=1e-5\n",
    "        length_scale_x=10,\n",
    "        reference_model=reference_conductivity_model,\n",
    "        reference_model_in_smooth=False\n",
    "    )\n",
    "\n",
    "# Define regularization parameters:\n",
    "reg_L2.alpha_s = 1e-5 # alpha_s\n",
    "reg_L2.alpha_x=1 # alpha_x\n",
    "\n",
    "### Optimization ###\n",
    "\n",
    "opt_L2 = optimization.InexactGaussNewton(\n",
    "    maxIter=100, maxIterLS=20, maxIterCG=20, tolCG=1e-3\n",
    ")\n",
    "\n",
    "### Inversion ###\n",
    "\n",
    "inv_prob_L2 = inverse_problem.BaseInvProblem(dmis_L2, reg_L2, opt_L2)\n",
    "\n",
    "#Inversion Directives\n",
    "update_jacobi = directives.UpdatePreconditioner(update_every_iteration=False)\n",
    "starting_beta = directives.BetaEstimate_ByEig(beta0_ratio=5)\n",
    "beta_schedule = directives.BetaSchedule(coolingFactor=1.5, coolingRate=2)\n",
    "target_misfit = directives.TargetMisfit(chifact=1.0)\n",
    "save_L2 = directives.SaveOutputDictEveryIteration()\n",
    "\n",
    "directives_list_L2 = [\n",
    "    update_jacobi,\n",
    "    starting_beta,\n",
    "    beta_schedule,\n",
    "    target_misfit,\n",
    "    save_L2\n",
    "]\n",
    "\n",
    "### Inversion ###\n",
    "\n",
    "# Combine the inverse problem and the set of directives\n",
    "inv_L2 = inversion.BaseInversion(inv_prob_L2, directives_list_L2)\n",
    "\n",
    "# Run the inversion\n",
    "# print(f\"\\n **** Running layered inversion for line {line_no} and station {stn}... ****\")\n",
    "recovered_model_L2 = inv_L2.run(starting_conductivity_model)\n",
    "\n",
    "resistivities_L2 = 1 / (log_conductivity_map * recovered_model_L2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
